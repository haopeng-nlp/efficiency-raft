{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1TQtHG-Wf2CgYGSD9e7_uJWIdiK5HNniV)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting started with the RAFT benchmark\n",
    "\n",
    "In this notebook, we will walk through:\n",
    "\n",
    "1. Loading the tasks from the [RAFT dataset](https://huggingface.co/datasets/ought/raft)\n",
    "2. Creating a classifier using any CausalLM from the [Hugging Face Hub](https://huggingface.co/models)\n",
    "3. Generating predictions using that classifier for RAFT test examples\n",
    "\n",
    "This should provide you with the steps needed to make a submission to the [RAFT leaderboard](https://huggingface.co/spaces/ought/raft-leaderboard)!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import datasets\n",
    "\n",
    "datasets.logging.set_verbosity_error()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading RAFT datasets\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll focus on the ADE corpus V2 task in this starter kit, but similar code could be run for all of the tasks in RAFT. To see the possible tasks, we can use the following function from `datasets`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "RAFT_TASKS = get_dataset_config_names(\"ought/raft\")\n",
    "RAFT_TASKS"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ade_corpus_v2',\n",
       " 'banking_77',\n",
       " 'terms_of_service',\n",
       " 'tai_safety_research',\n",
       " 'neurips_impact_statement_risks',\n",
       " 'overruling',\n",
       " 'systematic_review_inclusion',\n",
       " 'one_stop_english',\n",
       " 'tweet_eval_hate',\n",
       " 'twitter_complaints',\n",
       " 'semiconductor_org_types']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each task in RAFT consists of a training set of only **_50 labeled examples_** and an unlabeled test set. All labels have a textual version associated with them. Let's load corpus associated with the `ade_corpus_v2` task:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "TASK = \"ade_corpus_v2\"\n",
    "raft_dataset = load_dataset(\"ought/raft\", name=TASK)\n",
    "raft_dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Sentence', 'ID', 'Label'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Sentence', 'ID', 'Label'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `raft_dataset` object itself is a [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training and test sets. In this task we can see we have 50 labelled examples to work with and 5,000 examples on the test set we need to generate predictions for. To access an example, you need to specify the name of the split and then the index as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "raft_dataset[\"train\"][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Sentence': 'No regional side effects were noted.', 'ID': 0, 'Label': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we can see that each example is assigned a label ID which denotes the class in this particular tasks. Let's check how many classes we have in the training set:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "label_ids = raft_dataset[\"train\"].unique(\"Label\")\n",
    "label_ids"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Okay, this indicates that `ade_corpus_v2` is a binary classification task and we can extract the human-readable label names as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "features = raft_dataset[\"train\"].features[\"Label\"]\n",
    "id2label = {idx : features.int2str(idx) for idx in label_ids}\n",
    "id2label"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{2: 'not ADE-related', 1: 'ADE-related'}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the test set also has a `Label` entry, but it is zero to denote a dummy label (this is what your model needs to predict!):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "raft_dataset[\"test\"].unique(\"Label\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To get a broader sense of what kind of data we are dealing with, we can use the following function to randomly sample from the corpus and display the results as a table:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "show_random_elements(raft_dataset[\"train\"])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CT-scan disclosed right ethmoid sinusitis that spread to the orbit after surgery.</td>\n",
       "      <td>22</td>\n",
       "      <td>not ADE-related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMPLICATIONS: Dexmedetomidine, an alpha(2)-adrenoceptor agonist, is indicated for sedating patients on mechanical ventilation.</td>\n",
       "      <td>43</td>\n",
       "      <td>not ADE-related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The INR should be monitored more frequently when bosentan is initiated, adjusted, or discontinued in patients taking warfarin.</td>\n",
       "      <td>2</td>\n",
       "      <td>not ADE-related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remarkable findings on initial examination were facial grimacing, flexure posturing of both upper extremities, and 7-mm, reactive pupils.</td>\n",
       "      <td>44</td>\n",
       "      <td>not ADE-related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONCLUSION: Pancreatic enzyme intolerance, although rare, would be a major problem in the management of patients with CF.</td>\n",
       "      <td>6</td>\n",
       "      <td>not ADE-related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After the first oral dose of propranolol, syncope developed together with atrioventricular block.</td>\n",
       "      <td>3</td>\n",
       "      <td>ADE-related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acute promyelocytic leukemia after living donor partial orthotopic liver transplantation in two Japanese girls.</td>\n",
       "      <td>45</td>\n",
       "      <td>not ADE-related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The patient had no skin reactions for the next 12 mo, with the exception of injection-site papules.</td>\n",
       "      <td>18</td>\n",
       "      <td>not ADE-related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sotalol-induced bradycardia reversed by glucagon.</td>\n",
       "      <td>23</td>\n",
       "      <td>ADE-related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We describe a patient who developed HUS after treatment with mitomycin C (total dose 144 mg/m2) due to a carcinoma of the ascending colon.</td>\n",
       "      <td>30</td>\n",
       "      <td>ADE-related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a classifier from the Hugging Face Model Hub"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We provide a class which uses the same prompt construction method as our GPT-3 baseline, but works with any CausalLM on the [HuggingFace Model Hub](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads). The classifier will automatically use a GPU if available. Brief documentation on the arguments for configuring the classifier is provided below.:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from raft_baselines.classifiers import TransformersCausalLMClassifier\n",
    "\n",
    "classifier = TransformersCausalLMClassifier(\n",
    "    model_type=\"distilgpt2\",             # The model to use from the HF hub\n",
    "    training_data=raft_dataset[\"train\"],            # The training data\n",
    "    num_prompt_training_examples=25,     # See raft_predict.py for the number of training examples used on a per-dataset basis in the GPT-3 baselines run.\n",
    "                                         # Note that it may be better to use fewer training examples and/or shorter instructions with other models with smaller context windows.\n",
    "    add_prefixes=(TASK==\"banking_77\"),   # Set to True when using banking_77 since multiple classes start with the same token\n",
    "    config=TASK,                         # For task-specific instructions and field ordering\n",
    "    use_task_specific_instructions=True,\n",
    "    do_semantic_selection=True,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating predictions for RAFT test examples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to generate predictions on the test set, we need to provide the model with an appropriate prompt with the instructions. Let's take a look at how this works on a single example from the test set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example prompt and prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `TransformersCausalLMClassifier` has a `classify` function that will automatically generate the predicted probabilites from the model. We'll set `should_print_prompt=True` so that we can see which prompt is being used to instruct the model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "test_dataset = raft_dataset[\"test\"]\n",
    "first_test_example = test_dataset[0]\n",
    "\n",
    "# delete the 0 Label\n",
    "del first_test_example[\"Label\"]\n",
    "\n",
    "# probabilities for all classes\n",
    "output_probs = classifier.classify(first_test_example, should_print_prompt=True)\n",
    "output_probs"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label the sentence based on whether it is related to an adverse drug effect (ADE). Details are described below:\n",
      "Drugs: Names of drugs and chemicals that include brand names, trivial names, abbreviations and systematic names were annotated. Mentions of drugs or chemicals should strictly be in a therapeutic context. This category does not include the names of metabolites, reaction byproducts, or hospital chemicals (e.g. surgical equipment disinfectants).\n",
      "Adverse effect: Mentions of adverse effects include signs, symptoms, diseases, disorders, acquired abnormalities, deficiencies, organ damage or death that strictly occur as a consequence of drug intake.\n",
      "Possible labels:\n",
      "1. ADE-related\n",
      "2. not ADE-related\n",
      "\n",
      "Sentence: Treatment of silastic catheter-induced central vein septic thrombophlebitis\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: We describe a patient who developed HUS after treatment with mitomycin C (total dose 144 mg\n",
      "Label: ADE-related\n",
      "\n",
      "Sentence: In 1991 the patient were found to be seropositive for HCV antibodies as detected by\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: METHODS: We identified three patients who developed skin necrosis and determined any factors, which\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: These cases were considered unusual in light of the short delay of their onset after initiation of immunosupp\n",
      "Label: ADE-related\n",
      "\n",
      "Sentence: No regional side effects were noted.\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: A patient with psoriasis is described who had an abnormal response to the glucose tolerance test without other\n",
      "Label: ADE-related\n",
      "\n",
      "Sentence: CONCLUSIONS: These results suggest that clozapine may cause TD; however, the prevalence\n",
      "Label: ADE-related\n",
      "\n",
      "Sentence: The cases are important in documenting that drug-induced dystonias do occur in patients with dementia,\n",
      "Label: ADE-related\n",
      "\n",
      "Sentence: NEH must be considered in lupus patients receiving cytotoxic agents to avoid inappropriate use\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: A closer look at septic shock.\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: The mechanism by which sunitinib induces gynaecomastia is thought to be associated\n",
      "Label: ADE-related\n",
      "\n",
      "Sentence: Of the 16 patients, including the 1 reported here, only 3 displayed significant shortening of the\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: Sotalol-induced bradycardia reversed by glucagon.\n",
      "Label: ADE-related\n",
      "\n",
      "Sentence: CONCLUSION: Pancreatic enzyme intolerance, although rare, would be a major problem in\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: Macular infarction after endophthalmitis treated with vitrectomy and intravit\n",
      "Label: ADE-related\n",
      "\n",
      "Sentence: MRI has a high sensitivity and specificity in the diagnosis of osteonecrosis and should be used\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: IMPLICATIONS: Dexmedetomidine, an alpha(2)-adrenoceptor\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: The INR should be monitored more frequently when bosentan is initiated, adjusted, or discontinued\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: Remarkable findings on initial examination were facial grimacing, flexure posturing of both upper extrem\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: Early detection of these cases has practical importance since the identification and elimination of the causative drug is\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: This report demonstrates the increased risk of complicated varicella associated with the use of corticoster\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: These results indicate that the hyponatremia in this case was due to SIADH\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: Best-corrected visual acuity measurements were performed at every visit.\n",
      "Label: not ADE-related\n",
      "\n",
      "Sentence: OBJECTIVE: To describe onset of syndrome of inappropriate antidiuretic hormone (SIADH\n",
      "Label: ADE-related\n",
      "\n",
      "Sentence: CONCLUSIONS: SD-OCT and AO detected abnormalities that correlate topographically with visual field loss from hydroxychloroquine toxicity as demonstrated by HVF 10-2 and may be useful in the detection of subclinical abnormalities that precede symptoms or objective visual field loss.\n",
      "Label:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ADE-related': 0.31358153, 'not ADE-related': 0.68641853}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example we can see the model predicts that the example is not related to an adverse drug effect. We can use this technique to generate predictions across the whole test set! Let's take a look."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a submission file of predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To submit to the RAFT leaderboard, you'll need to provide a CSV file of predictions on the test set for each task (see [here](https://huggingface.co/datasets/ought/raft-submission) for detailed instructions).  The following code snippet generates a CSV with predictions for the first $N$ test examples in the format required for submission $(ID, Label)$. \n",
    "\n",
    "Note that this is expected to generate predictions of all \"Not ADE-related\" for the 10 test examples with the code as written; few-shot classification is pretty hard!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Increase this to len(test_dataset) to generate predictions over the full test set\n",
    "N_TEST = 10\n",
    "test_examples_to_predict = test_dataset.select(range(N_TEST))\n",
    "\n",
    "def predict_one(clf, test_example):\n",
    "    del test_example[\"Label\"]    \n",
    "    output_probs = clf.classify(example)\n",
    "    output_label = max(output_probs.items(), key=lambda kv_pair: kv_pair[1])[0]\n",
    "    return output_label\n",
    "\n",
    "data = []\n",
    "for example in test_examples_to_predict:\n",
    "    data.append({\"ID\": example[\"ID\"], \"Label\": predict_one(classifier, example)})\n",
    "    \n",
    "result_df = pd.DataFrame(data=data, columns=[\"ID\", \"Label\"]).astype({\"ID\": int, \"Label\": str})   \n",
    "result_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the `ID` column starts from index 50 since we have IDs 0-49 in the training set. The final step is to save the DataFrame as a CSV file and build out the rest of your submission:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result_df.to_csv(\"../data/example_predictions.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Good luck with the rest of the benchmark!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74118a50156796984ad06a64d88792c5d24753e439e2427f4985fcb9d71e695f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('raft-baselines': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}